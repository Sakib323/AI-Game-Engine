{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5e4ebd-871f-49cb-aa32-d6b733649824",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (1.2.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2024.12.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd29d98-567f-4e2d-8800-c629897ee27c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (0.8.1)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.11/site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from timm) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from timm) (0.21.0+cu124)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mfatal: destination path 'AI-Game-Engine' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!pip install einops timm\n",
    "\n",
    "import sys, os\n",
    "!git clone https://github.com/Sakib323/AI-Game-Engine.git\n",
    "sys.path.append('/workspace/AI-Game-Engine') \n",
    "from mmfreelm.models.hgrn_bit.mesh_dit import MeshDiT_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758745a5-af2e-420d-a72b-3bba2d33994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda, dtype: torch.float32\n",
      "SUCCESS: MeshDiT models imported!\n"
     ]
    }
   ],
   "source": [
    "import os, json, shutil, logging, random, signal, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, Subset, RandomSampler, SequentialSampler, DataLoader\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from diffusers import DDIMScheduler\n",
    "from safetensors.torch import load_file as safetensors_load\n",
    "import wandb\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True   \n",
    "torch._dynamo.config.verbose = False\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "print(f\"Using device: {device}, dtype: {dtype}\")              \n",
    "\n",
    "print(\"SUCCESS: MeshDiT models imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9420115-2dc4-47e9-a133-2982f88941a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (2024.12.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading from https://www.kaggle.com/api/v1/datasets/download/sakibahmed2022/meshdit-all-data-5-pt?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.1G/44.1G [05:51<00:00, 135MB/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /root/.cache/kagglehub/datasets/sakibahmed2022/meshdit-all-data-5-pt/versions/1\n",
      "Copying all_data.pt → /tmp/meshdit_cache/all_data.pt\n",
      "Copying all_data_1.pt → /tmp/meshdit_cache/all_data_1.pt\n",
      "Copying all_data_2.pt → /tmp/meshdit_cache/all_data_2.pt\n",
      "Copying all_data_3.pt → /tmp/meshdit_cache/all_data_3.pt\n",
      "Copying all_data_4.pt → /tmp/meshdit_cache/all_data_4.pt\n",
      "All .pt files ready in /tmp/meshdit_cache\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"sakibahmed2022/meshdit-all-data-5-pt\")\n",
    "print(\"Dataset downloaded to:\", path)\n",
    "cache_dir = \"/tmp/meshdit_cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "file_names = [\"all_data.pt\", \"all_data_1.pt\", \"all_data_2.pt\", \"all_data_3.pt\", \"all_data_4.pt\"]\n",
    "local_paths = []\n",
    "\n",
    "for name in file_names:\n",
    "    src = os.path.join(path, name)\n",
    "    dst = os.path.join(cache_dir, name)\n",
    "    \n",
    "    if not os.path.exists(dst):\n",
    "        print(f\"Copying {name} → {dst}\")\n",
    "        shutil.copy2(src, dst)\n",
    "    else:\n",
    "        print(f\"Already cached: {dst}\")\n",
    "        \n",
    "    local_paths.append(dst)\n",
    "\n",
    "print(\"All .pt files ready in\", cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbbca08-09f0-4390-8e3f-9ed0facad6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Freeing Disk Space ---\n",
      "Deleting original Kaggle cache at: /root/.cache/kagglehub/datasets/sakibahmed2022/meshdit-all-data-5-pt/versions/1\n",
      "✅ Redundant dataset deleted.\n",
      "\n",
      "DISK SPACE REMAINING: 70 GB\n",
      "All .pt files ready in /tmp/meshdit_cache\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Freeing Disk Space ---\")\n",
    "\n",
    "if os.path.exists(path):\n",
    "    print(f\"Deleting original Kaggle cache at: {path}\")\n",
    "    shutil.rmtree(path)\n",
    "    print(\"✅ Redundant dataset deleted.\")\n",
    "\n",
    "total, used, free = shutil.disk_usage(\"/\")\n",
    "print(f\"\\nDISK SPACE REMAINING: {free // (2**30)} GB\")\n",
    "print(\"All .pt files ready in\", cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15a24b-4306-45a4-8e61-580945ff0b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msakibahmed2018go\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 97,308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbe55cc1f3a49b6a58c785e72bec749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302b73b9481b46eba3936a33ad6b8167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a508ed085d4a8ab9967b87b57fec1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce564d95f2046fe8274e7596e05d1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PHASE 1 : MeshDiT-S from scratch ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20251120_175331-hmm3grcx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sakibahmed2018go/mesh-dit-3d-generation/runs/hmm3grcx' target=\"_blank\">MeshDiT-S</a></strong> to <a href='https://wandb.ai/sakibahmed2018go/mesh-dit-3d-generation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sakibahmed2018go/mesh-dit-3d-generation' target=\"_blank\">https://wandb.ai/sakibahmed2018go/mesh-dit-3d-generation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sakibahmed2018go/mesh-dit-3d-generation/runs/hmm3grcx' target=\"_blank\">https://wandb.ai/sakibahmed2018go/mesh-dit-3d-generation/runs/hmm3grcx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mmfreelm.models.hgrn_bit.mesh_dit:Absolute positional embeddings are disabled for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n",
      "Initializing RotaryEmbedding with theta=10000.0 and ternary=True\n",
      "\n",
      "[RotaryEmbedding] Initialized with: dim=64, max_pos=2048, base=10000.0, ternary=True\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] WON'T CONVERT torch_dynamo_resume_in_forward_at_136 /workspace/AI-Game-Engine/mmfreelm/layers/hgrn_bit.py line 136 \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1036, in _compile\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     raise InternalTorchDynamoError(\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 659, in wrapper\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_fn(self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2341, in CALL\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self._call(inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2335, in _call\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.call_function(fn, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 897, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 317, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return super().call_function(tx, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 118, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 903, in inline_user_function_return\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 3072, in inline_call\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 3198, in inline_call_\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 659, in wrapper\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_fn(self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2341, in CALL\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self._call(inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2335, in _call\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.call_function(fn, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 897, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 1022, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.obj.call_method(tx, self.name, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 759, in call_method\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.call_apply(tx, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 681, in call_apply\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     ).call_function(tx, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 991, in tree_map\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return treespec.unflatten(map(func, *flat_args))\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 830, in unflatten\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     leaves = list(leaves)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in <lambda>\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                                                       ^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.InternalTorchDynamoError: AttributeError: 'NoneType' object has no attribute 'node'\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] from user code:\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]    File \"/workspace/AI-Game-Engine/mmfreelm/layers/hgrn_bit.py\", line 152, in torch_dynamo_resume_in_forward_at_136\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     o, recurrent_state = fused_recurrent_hgrn(i, f, initial_state=recurrent_state, output_final_state=use_cache)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/workspace/AI-Game-Engine/mmfreelm/ops/hgrn/recurrent_fuse.py\", line 184, in fused_recurrent_hgrn\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     o, final_state = FusedRecurrentHGRNFunction.apply(x, g, initial_state, output_final_state)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1036, in _compile\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     raise InternalTorchDynamoError(\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 659, in wrapper\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_fn(self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2341, in CALL\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self._call(inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2335, in _call\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.call_function(fn, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 897, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 317, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return super().call_function(tx, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 118, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 903, in inline_user_function_return\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 3072, in inline_call\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 3198, in inline_call_\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 659, in wrapper\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_fn(self, inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2341, in CALL\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self._call(inst)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2335, in _call\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.call_function(fn, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 897, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 1022, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.obj.call_method(tx, self.name, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 759, in call_method\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.call_apply(tx, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 681, in call_apply\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     ).call_function(tx, args, kwargs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in call_function\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 991, in tree_map\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return treespec.unflatten(map(func, *flat_args))\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 830, in unflatten\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     leaves = list(leaves)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in <lambda>\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                                                       ^^^^^^\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.InternalTorchDynamoError: AttributeError: 'NoneType' object has no attribute 'node'\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] from user code:\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]    File \"/workspace/AI-Game-Engine/mmfreelm/layers/hgrn_bit.py\", line 152, in torch_dynamo_resume_in_forward_at_136\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     o, recurrent_state = fused_recurrent_hgrn(i, f, initial_state=recurrent_state, output_final_state=use_cache)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/workspace/AI-Game-Engine/mmfreelm/ops/hgrn/recurrent_fuse.py\", line 184, in fused_recurrent_hgrn\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     o, final_state = FusedRecurrentHGRNFunction.apply(x, g, initial_state, output_final_state)\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1120 17:54:01.958000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] WON'T CONVERT fused_recurrent_hgrn /workspace/AI-Game-Engine/mmfreelm/ops/hgrn/recurrent_fuse.py line 176 \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1036, in _compile\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     raise InternalTorchDynamoError(\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 659, in wrapper\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_fn(self, inst)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2341, in CALL\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self._call(inst)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2335, in _call\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.call_function(fn, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 897, in call_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 1022, in call_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.obj.call_method(tx, self.name, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 759, in call_method\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.call_apply(tx, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 681, in call_apply\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     ).call_function(tx, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in call_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 991, in tree_map\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return treespec.unflatten(map(func, *flat_args))\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 830, in unflatten\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     leaves = list(leaves)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in <lambda>\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                                                       ^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.InternalTorchDynamoError: AttributeError: 'NoneType' object has no attribute 'node'\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] from user code:\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]    File \"/workspace/AI-Game-Engine/mmfreelm/ops/hgrn/recurrent_fuse.py\", line 184, in fused_recurrent_hgrn\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     o, final_state = FusedRecurrentHGRNFunction.apply(x, g, initial_state, output_final_state)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1036, in _compile\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     raise InternalTorchDynamoError(\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 659, in wrapper\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return inner_fn(self, inst)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2341, in CALL\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self._call(inst)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2335, in _call\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.call_function(fn, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 897, in call_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 1022, in call_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.obj.call_method(tx, self.name, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 759, in call_method\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return self.call_apply(tx, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/misc.py\", line 681, in call_apply\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     ).call_function(tx, args, kwargs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in call_function\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 991, in tree_map\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     return treespec.unflatten(map(func, *flat_args))\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py\", line 830, in unflatten\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     leaves = list(leaves)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]   File \"/opt/conda/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py\", line 2531, in <lambda>\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     new_fwd_graph_outputs = pytree.tree_map(lambda x: x.node, new_fwd_graph_outputs)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]                                                       ^^^^^^\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.InternalTorchDynamoError: AttributeError: 'NoneType' object has no attribute 'node'\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] from user code:\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]    File \"/workspace/AI-Game-Engine/mmfreelm/ops/hgrn/recurrent_fuse.py\", line 184, in fused_recurrent_hgrn\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233]     o, final_state = FusedRecurrentHGRNFunction.apply(x, g, initial_state, output_final_state)\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1120 17:54:03.673000 5356 site-packages/torch/_dynamo/convert_frame.py:1233] \n",
      "W1120 17:54:47.990000 5356 site-packages/torch/_dynamo/convert_frame.py:906] [9/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1120 17:54:47.990000 5356 site-packages/torch/_dynamo/convert_frame.py:906] [9/8]    function: 'wrapper' (/workspace/AI-Game-Engine/mmfreelm/utils.py:7)\n",
      "W1120 17:54:47.990000 5356 site-packages/torch/_dynamo/convert_frame.py:906] [9/8]    last reason: 9/0: tensor 'L['args'][0]' dtype mismatch. expected Half, actual Float\n",
      "W1120 17:54:47.990000 5356 site-packages/torch/_dynamo/convert_frame.py:906] [9/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1120 17:54:47.990000 5356 site-packages/torch/_dynamo/convert_frame.py:906] [9/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1614' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1614/1720 2:58:25 < 11:43, 0.15 it/s, Epoch 9.38/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.079304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.075536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.073858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model():\n",
    "    # ------------------- W&B -------------------\n",
    "    WANDB_TOKEN = \"89b06c10468af620747b4bd340f72fa5d56f6849\"\n",
    "    try:\n",
    "        wandb.login(key=WANDB_TOKEN)\n",
    "        use_wandb = True\n",
    "    except Exception as e:\n",
    "        print(\"W&B disabled:\", e)\n",
    "        use_wandb = False\n",
    "\n",
    "    # ------------------- Dataset -------------------\n",
    "    class CustomDataCollator:\n",
    "        def __call__(self, features):\n",
    "            batch = {}\n",
    "            batch['x'] = torch.stack([f['x'] for f in features])\n",
    "            y_features = [f['y'] for f in features]\n",
    "            batch['y'] = {k: torch.stack([d[k] for d in y_features]) for k in y_features[0]}\n",
    "            return batch\n",
    "\n",
    "    class MeshDiTTrainer(Trainer):\n",
    "        def __init__(self, *args, noise_scheduler, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.noise_scheduler = noise_scheduler\n",
    "\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "            x_start = inputs[\"x\"]\n",
    "            model_kwargs = inputs[\"y\"]\n",
    "            \n",
    "            noise = torch.randn_like(x_start)\n",
    "            timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps,\n",
    "                                      (x_start.shape[0],), device=x_start.device).long()\n",
    "            \n",
    "            noisy_latents = self.noise_scheduler.add_noise(x_start, noise, timesteps)\n",
    "            \n",
    "            # Forward pass\n",
    "            noise_pred = model(noisy_latents, timesteps, model_kwargs)\n",
    "            \n",
    "            loss = F.huber_loss(noise_pred, noise, delta=1.0)\n",
    "            return (loss, {\"loss\": loss}) if return_outputs else loss\n",
    "\n",
    "        def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "            \"\"\"\n",
    "            Custom prediction step for Diffusion validation.\n",
    "            Generates noise/timesteps on the fly and computes loss on the validation set.\n",
    "            \"\"\"\n",
    "            # CRITICAL FIX: Move inputs to the correct device (GPU)\n",
    "            inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x_start = inputs[\"x\"]\n",
    "                model_kwargs = inputs[\"y\"]\n",
    "\n",
    "                # Generate noise and timesteps for validation batch\n",
    "                noise = torch.randn_like(x_start)\n",
    "                timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps,\n",
    "                                          (x_start.shape[0],), device=x_start.device).long()\n",
    "\n",
    "                noisy_latents = self.noise_scheduler.add_noise(x_start, noise, timesteps)\n",
    "\n",
    "                # Forward pass\n",
    "                noise_pred = model(noisy_latents, timesteps, model_kwargs)\n",
    "                \n",
    "                loss = F.huber_loss(noise_pred, noise, delta=1.0)\n",
    "\n",
    "            # Return (loss, logits, labels). Logits/Labels are None because we only track loss.\n",
    "            return (loss, None, None)\n",
    "\n",
    "    class ConcatenatedMeshDataset(Dataset):\n",
    "        def __init__(self, pt_paths):\n",
    "            self.pt_paths = pt_paths\n",
    "            self.cumsum = [0]\n",
    "            self.lengths = []\n",
    "            self.file_handles = []\n",
    "            for p in pt_paths:\n",
    "                handle = torch.load(p, map_location='cpu', mmap=True)\n",
    "                data = handle['data']\n",
    "                L = len(data)\n",
    "                self.lengths.append(L)\n",
    "                self.cumsum.append(self.cumsum[-1] + L)\n",
    "                self.file_handles.append(data)\n",
    "            print(f\"Total samples: {sum(self.lengths):,}\")\n",
    "\n",
    "        def __len__(self): return self.cumsum[-1]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            for i, cum in enumerate(self.cumsum):\n",
    "                if idx < cum: break\n",
    "            file_idx = i - 1\n",
    "            local_idx = idx - self.cumsum[file_idx]\n",
    "            sample = self.file_handles[file_idx][local_idx]\n",
    "            return {'x': sample['x'], 'y': sample['y']}\n",
    "\n",
    "    # Assuming 'local_paths', 'MeshDiT_models', 'device', and 'dtype' are defined globally\n",
    "    full_dataset = ConcatenatedMeshDataset(local_paths)\n",
    "\n",
    "    total = len(full_dataset)\n",
    "    eval_size = max(1, int(total * 0.10))\n",
    "    train_size = total - eval_size\n",
    "    train_subset = Subset(full_dataset, range(eval_size, total))\n",
    "    eval_subset = Subset(full_dataset, range(eval_size))\n",
    "\n",
    "    train_sampler = RandomSampler(train_subset, generator=torch.Generator().manual_seed(42))\n",
    "    eval_sampler = SequentialSampler(eval_subset)\n",
    "    collator = CustomDataCollator()\n",
    "    scheduler = DDIMScheduler(num_train_timesteps=2000,\n",
    "                              beta_schedule=\"linear\",\n",
    "                              prediction_type=\"epsilon\",\n",
    "                              clip_sample=False)\n",
    "\n",
    "    # ------------------- Tokenizer -------------------\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Sakib323/MMfreeLM-370M\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # ------------------- PHASE 1 (scratch) -------------------\n",
    "    print(\"\\n=== PHASE 1 : MeshDiT-S from scratch ===\")\n",
    "\n",
    "    if use_wandb:\n",
    "        os.environ[\"WANDB_PROJECT\"] = \"mesh-dit-3d-generation-vast\"\n",
    "        wandb.init(project=\"mesh-dit-3d-generation\", name=\"MeshDiT-S\", reinit=True)\n",
    "\n",
    "    model_p1 = MeshDiT_models['MeshDiT-S'](\n",
    "        input_tokens=2048,\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        use_rope=True,\n",
    "        use_ternary_rope=True,\n",
    "        image_condition=False,\n",
    "        full_precision=True,\n",
    "        optimized_bitlinear=False,\n",
    "    ).to(device, dtype=dtype)\n",
    "\n",
    "    args_p1 = TrainingArguments(\n",
    "        output_dir=\"./phase1_ckpt\",\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=64,\n",
    "        gradient_accumulation_steps=8,\n",
    "        learning_rate=1e-4,\n",
    "        lr_scheduler_type=\"cosine\",  \n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1000,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        fp16=True,\n",
    "        max_grad_norm=5.0,          \n",
    "        dataloader_num_workers=4,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"wandb\" if use_wandb else \"tensorboard\",\n",
    "        run_name=\"MeshDiT-S-Phase1-Final\",\n",
    "        torch_compile=True,        \n",
    "        torch_compile_backend=\"inductor\",\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_prefetch_factor=4,\n",
    "    )\n",
    "\n",
    "    trainer_p1 = MeshDiTTrainer(\n",
    "        model=model_p1,\n",
    "        args=args_p1,\n",
    "        train_dataset=train_subset,\n",
    "        eval_dataset=eval_subset,\n",
    "        data_collator=collator,\n",
    "        noise_scheduler=scheduler,\n",
    "    )\n",
    "\n",
    "    trainer_p1.train_dataloader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=args_p1.per_device_train_batch_size,\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=collator,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=4,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    trainer_p1.eval_dataloader = DataLoader(\n",
    "        eval_subset,\n",
    "        batch_size=args_p1.per_device_train_batch_size,\n",
    "        sampler=eval_sampler,\n",
    "        collate_fn=collator,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    trainer_p1.train()\n",
    "    trainer_p1.save_model(\"./mesh_dit_final\")\n",
    "    tokenizer.save_pretrained(\"./mesh_dit_final\")\n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    print(\"FINAL MODEL → ./mesh_dit_final\")\n",
    "\n",
    "    print(\"\\nTRAINING COMPLETE – MeshDiT-B ready!\")\n",
    "\n",
    "# Run it\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edc13a-7bb8-43cb-aa04-4544c8f2d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shlex\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "KAGGLE_USERNAME = \"sakibahmed2022\"\n",
    "KAGGLE_KEY = \"d0ec7fe8091a3906c6995568c11e9e58\"\n",
    "os.environ['KAGGLE_USERNAME'] = KAGGLE_USERNAME\n",
    "os.environ['KAGGLE_KEY'] = KAGGLE_KEY\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. CONFIG\n",
    "# --------------------------------------------------------------\n",
    "DESIRED_SLUG    = f\"{KAGGLE_USERNAME}/meshdit-trained-model\"\n",
    "LOCAL_DIR       = \"./mesh_dit_final\"\n",
    "TITLE           = \"MeshDiT S Trained Model 10 epoch\"\n",
    "VERSION_MSG     = f\"Upload final model – {datetime.utcnow().isoformat()} UTC\"\n",
    "PUBLIC          = False          # private dataset\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3. Helper – write dataset-metadata.json (required)\n",
    "# --------------------------------------------------------------\n",
    "def write_metadata(folder: str, dataset_id: str):\n",
    "    meta = {\n",
    "        \"title\": TITLE,\n",
    "        \"id\": dataset_id,\n",
    "        \"licenses\": [{\"name\": \"CC-BY-4.0\"}],\n",
    "        \"description\": f\"{TITLE} – uploaded {datetime.utcnow().isoformat()} UTC\"\n",
    "    }\n",
    "    path = os.path.join(folder, \"dataset-metadata.json\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "    print(f\"[meta] {path}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4. Try Python API (ignore harmless ApiStartBlobUploadRequest warning)\n",
    "# --------------------------------------------------------------\n",
    "def try_api(folder: str, dataset_id: str, msg: str):\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    # Try version first\n",
    "    try:\n",
    "        api.dataset_create_version(\n",
    "            folder=folder,\n",
    "            version_notes=msg,\n",
    "            convert_to_csv=False,\n",
    "            delete_old_versions=False,\n",
    "        )\n",
    "        print(\"[api] version created\")\n",
    "        return True, dataset_id\n",
    "    except Exception as e:\n",
    "        # 403 after files are uploaded → dataset already exists, fall back to CLI\n",
    "        if \"403\" in str(e):\n",
    "            print(\"[api] 403 after file upload → will use CLI\")\n",
    "            return False, dataset_id\n",
    "        # Dataset missing → create new\n",
    "        if \"does not exist\" in str(e).lower() or \"404\" in str(e):\n",
    "            print(\"[api] dataset missing → creating new\")\n",
    "            api.dataset_create_new(folder=folder, public=PUBLIC, convert_to_csv=False)\n",
    "            print(\"[api] new dataset created\")\n",
    "            return True, dataset_id\n",
    "        print(f\"[api] unexpected error: {e}\")\n",
    "        return False, None\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5. CLI fallback (no --private flag – CLI defaults to private)\n",
    "# --------------------------------------------------------------\n",
    "def try_cli(folder: str, dataset_id: str, msg: str):\n",
    "    # 1. version\n",
    "    cmd = f\"kaggle datasets version -p {shlex.quote(folder)} -m {shlex.quote(msg)}\"\n",
    "    print(f\"[cli] version: {cmd}\")\n",
    "    p = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if p.returncode == 0:\n",
    "        print(\"[cli] version OK\")\n",
    "        return True, dataset_id\n",
    "\n",
    "    # 2. create (only if version failed because dataset missing)\n",
    "    cmd = f\"kaggle datasets create -p {shlex.quote(folder)}\"\n",
    "    print(f\"[cli] create: {cmd}\")\n",
    "    p = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if p.returncode == 0:\n",
    "        print(\"[cli] create OK\")\n",
    "        return True, dataset_id\n",
    "\n",
    "    print(\"[cli] both commands failed\")\n",
    "    print(\"STDOUT:\", p.stdout)\n",
    "    print(\"STDERR:\", p.stderr)\n",
    "    return False, None\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6. Main – slug-collision safe\n",
    "# --------------------------------------------------------------\n",
    "def upload():\n",
    "    if not os.path.isdir(LOCAL_DIR):\n",
    "        raise FileNotFoundError(LOCAL_DIR)\n",
    "\n",
    "    files = [f for f in os.listdir(LOCAL_DIR) if os.path.isfile(os.path.join(LOCAL_DIR, f))]\n",
    "    print(\"[main] files:\", files)\n",
    "\n",
    "    # Resolve slug\n",
    "    dataset_id = DESIRED_SLUG\n",
    "    ts = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    alt = f\"{KAGGLE_USERNAME}/meshdit-trained-model-{ts}\"\n",
    "\n",
    "    # Try a cheap API call to see if the slug exists\n",
    "    try:\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        KaggleApi().authenticate()\n",
    "        KaggleApi().dataset_list_files(dataset_id)   # raises if missing\n",
    "        print(f\"[slug] '{dataset_id}' exists → using timestamped\")\n",
    "        dataset_id = alt\n",
    "    except Exception:\n",
    "        pass   # keep desired slug\n",
    "\n",
    "    write_metadata(LOCAL_DIR, dataset_id)\n",
    "\n",
    "    # 1. API\n",
    "    print(\"[main] trying Python API …\")\n",
    "    ok, final_id = try_api(LOCAL_DIR, dataset_id, VERSION_MSG)\n",
    "    if ok:\n",
    "        url = f\"https://www.kaggle.com/datasets/{final_id}\"\n",
    "        print(f\"[SUCCESS] API → {url}\")\n",
    "        return url\n",
    "\n",
    "    # 2. CLI\n",
    "    print(\"[main] API failed → CLI fallback …\")\n",
    "    ok, final_id = try_cli(LOCAL_DIR, dataset_id, VERSION_MSG)\n",
    "    if ok:\n",
    "        url = f\"https://www.kaggle.com/datasets/{final_id}\"\n",
    "        print(f\"[SUCCESS] CLI → {url}\")\n",
    "        return url\n",
    "\n",
    "    raise RuntimeError(\"Both API and CLI failed\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7. RUN\n",
    "# --------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    final_url = upload()\n",
    "    print(\"\\n=== FINAL URL ===\")\n",
    "    print(final_url)\n",
    "    print(\"\\nDownload with:\")\n",
    "    print(f\"kaggle datasets download -d {final_url.split('/')[-2]}/{final_url.split('/')[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
